{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.core.scaling import ConstScaling\n",
    "from brevitas.core.quant.int_base import IntQuant\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import linear\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "tensor([0.0200, 0.0000, 0.0200, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "int_quant = IntQuant(narrow_range=True, signed=False)\n",
    "print(torch.tensor(4.))\n",
    "scale, zero_point, bit_width = torch.tensor(0.01), torch.tensor(0.), torch.tensor(2.)\n",
    "inp = torch.Tensor([0.042, -0.053, 0.31, -0.44])\n",
    "out = int_quant(scale, zero_point, bit_width, inp)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para backward hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "    print('Inside class:' + self.__class__.__name__)\n",
    "    print('')\n",
    "    \"\"\"\n",
    "    print('grad_input: ', type(grad_input))\n",
    "    print('grad_input[0]: ', type(grad_input[0]))\n",
    "    print('grad_output: ', type(grad_output))\n",
    "    print('grad_output[0]: ', type(grad_output[0]))\n",
    "    print('')\n",
    "    print('grad_input size:', grad_input[0].size())\n",
    "    print('grad_output size:', grad_output[0].size())\n",
    "    print('grad_input norm:', grad_input[0].norm())\n",
    "    print(grad_input[0])\"\"\"\n",
    "\n",
    "    #print(type(grad_output[0]))\n",
    "    #grad_input[0][:] = 5#torch.round(input=grad_input[0],decimals=5)\n",
    "    if type(grad_input[0]) == torch.Tensor:\n",
    "        #print(\"Antes: \",grad_output[0])\n",
    "        grad_output[0][:] = 5\n",
    "        #print(\"Despues:\",grad_output[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de argumentos y datos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        #print(model.linear_relu_stack[0].weight.grad)\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, dry_run=False, epochs=6, gamma=0.7, log_interval=10, lr=1.0, no_cuda=False, save_model=False, seed=1, test_batch_size=1000)\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "            help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "            help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=6, metavar='N',\n",
    "            help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "            help='learning rate (default: 1.0)')\n",
    "parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "            help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "            help='disables CUDA training')\n",
    "parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "            help='quickly check a single pass')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "            help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "            help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save-model', action='store_true', default=False,\n",
    "            help='For Saving the current Model')\n",
    "args = parser.parse_args(\"\")\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "print(args)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "test_kwargs = {'batch_size': args.test_batch_size}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                'pin_memory': True,\n",
    "                'shuffle': True}\n",
    "train_kwargs.update(cuda_kwargs)\n",
    "test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #media y desviación típica de la base de datos MNIST\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "dataset1 = datasets.MNIST('./data', train=True, download=True,\n",
    "            transform=transform)\n",
    "dataset2 = datasets.MNIST('./data', train=False,\n",
    "            transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de la linear custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class LinearC(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(LinearC,self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.size_out = out_features\n",
    "        self.weight = nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        nn.init.xavier_normal_(self.weight,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = linear(x,self.weight,bias=None)\n",
    "        return torch.round(input=output,decimals=3)\"\"\"\n",
    "\n",
    "class LinearC(nn.Linear):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,device=None, dtype=None) -> None:\n",
    "        super().__init__(in_features,out_features,bias=bias,device=device,dtype=dtype)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        output = super().forward(x)\n",
    "        #print(output)\n",
    "        return output#torch.round(input=output,decimals=5)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28,4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.linear_relu_stack[0].register_full_backward_hook(printgradnorm)\n",
    "#net.linear_relu_stack[2].register_full_backward_hook(printgradnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomNet().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adadelta(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.216807\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.150828\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.285417\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.240645\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.183556\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.190336\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.229715\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.120216\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.161169\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.252653\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.203687\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.211934\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.219008\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.293447\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.160741\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.226797\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.249928\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.267389\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.210381\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.224570\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.194144\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.216853\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.247035\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.190971\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.199581\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.156476\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.190254\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.198551\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.232383\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.179479\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.209448\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.245986\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.234534\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.283715\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.219441\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.255460\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.252396\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.253196\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.174848\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.224875\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.267272\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.190259\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.301412\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.235068\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.146688\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.196515\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.234535\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.248707\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.197730\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.146238\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.157899\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.212020\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.218153\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.227142\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.243062\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.250205\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.243689\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.240119\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.247131\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.249626\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.188317\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.208680\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.229919\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.212354\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.230865\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.243601\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.159285\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 2.216568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(args, model, device, train_loader, optimizer, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/francisco/Documentos/ingenieria_informatica/cuarto_informatica/segundo_cuatri/TFG/TFG-Francisco-Jose-Aparicio-Martos/codigo/custom_layers.ipynb Cell 7'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francisco/Documentos/ingenieria_informatica/cuarto_informatica/segundo_cuatri/TFG/TFG-Francisco-Jose-Aparicio-Martos/codigo/custom_layers.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(args, model, device, train_loader, optimizer, epoch):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francisco/Documentos/ingenieria_informatica/cuarto_informatica/segundo_cuatri/TFG/TFG-Francisco-Jose-Aparicio-Martos/codigo/custom_layers.ipynb#ch0000018?line=1'>2</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/francisco/Documentos/ingenieria_informatica/cuarto_informatica/segundo_cuatri/TFG/TFG-Francisco-Jose-Aparicio-Martos/codigo/custom_layers.ipynb#ch0000018?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francisco/Documentos/ingenieria_informatica/cuarto_informatica/segundo_cuatri/TFG/TFG-Francisco-Jose-Aparicio-Martos/codigo/custom_layers.ipynb#ch0000018?line=3'>4</a>\u001b[0m         data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francisco/Documentos/ingenieria_informatica/cuarto_informatica/segundo_cuatri/TFG/TFG-Francisco-Jose-Aparicio-Martos/codigo/custom_layers.ipynb#ch0000018?line=4'>5</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1203'>1204</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1205'>1206</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1206'>1207</a>\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1207'>1208</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1208'>1209</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1209'>1210</a>\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1160'>1161</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1161'>1162</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1162'>1163</a>\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1163'>1164</a>\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1164'>1165</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=997'>998</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=998'>999</a>\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=999'>1000</a>\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1007'>1008</a>\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1008'>1009</a>\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1009'>1010</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1010'>1011</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1011'>1012</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1012'>1013</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1013'>1014</a>\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1014'>1015</a>\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1015'>1016</a>\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/queue.py?line=176'>177</a>\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/queue.py?line=177'>178</a>\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/queue.py?line=178'>179</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/queue.py?line=179'>180</a>\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/queue.py?line=180'>181</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/brevitas/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/threading.py?line=303'>304</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/threading.py?line=304'>305</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/threading.py?line=305'>306</a>\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/threading.py?line=306'>307</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/brevitas/lib/python3.8/threading.py?line=307'>308</a>\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args, model, device, train_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "output = net(tensor)\n",
    "loss = F.nll_loss(output,target)\n",
    "loss.backward()\n",
    "print(net.linear_relu_stack[0].weight.grad)\n",
    "print(net.linear_relu_stack[2].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modify(tensor):\n",
    "    tensor[1,1] = 0\n",
    "\n",
    "prueba = torch.ones(2,2)\n",
    "print(prueba)\n",
    "modify(prueba)\n",
    "prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54e7bf377929e003ce704e064372d86d515884b8fe63c4a918b625b8731f2a8b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('brevitas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
