@article{RefWorks:RefID:4-schuman2022opportunities,
	author={Catherine D. Schuman and Shruti R. Kulkarni and Maryam Parsa and J. Parker Mitchell and Prasanna Date and Bill Kay},
	year={2022},
	month={-01},
	title={Opportunities for neuromorphic computing algorithms and applications},
	journal={Nature Computational Science},
	volume={2},
	number={1},
	pages={10-19},
	abstract={There is still a wide variety of challenges that restrict the rapid growth of neuromorphic algorithmic and application development. Addressing these challenges is essential for the research community to be able to effectively use neuromorphic computers in the future.},
	isbn={2662-8457},
	url={https://www.nature.com/articles/s43588-021-00184-y},
	doi={10.1038/s43588-021-00184-y}
}

@article{RefWorks:RefID:6-rumelhart1986learning,
	author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
	year={1986},
	month={Oct 9,},
	title={Learning representations by back-propagating errors},
	journal={Nature (London)},
	volume={323},
	number={6088},
	pages={533-536},
	abstract={We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	isbn={0028-0836},
	url={http://dx.doi.org/10.1038/323533a0},
	doi={10.1038/323533a0}
}

@article{RefWorks:RefID:8-lillicrap2020backpropagation,
	author={Timothy P. Lillicrap and Adam Santoro and Luke Marris and Colin J. Akerman and Geoffrey Hinton},
	year={2020},
	month={-06},
	title={Backpropagation and the brain},
	journal={Nature Reviews Neuroscience},
	volume={21},
	number={6},
	pages={335-346},
	abstract={The backpropagation of error (backprop) algorithm is frequently used to train deep neural networks in machine learning, but it has not been viewed as being implemented by the brain. In this Perspective, however, Lillicrap and colleagues argue that the key principles underlying backprop may indeed have a role in brain function.},
	isbn={1471-0048},
	url={https://www.nature.com/articles/s41583-020-0277-3},
	doi={10.1038/s41583-020-0277-3}
}

@article{RefWorks:RefID:9-lillicrap2016random,
	author={Timothy P. Lillicrap and Daniel Cownden and Douglas B. Tweed and Colin J. Akerman},
	year={2016},
	month={-11-08},
	title={Random synaptic feedback weights support error backpropagation for deep learning},
	journal={Nature Communications},
	volume={7},
	number={1},
	pages={1-10},
	abstract={Multi-layered neural architectures that implement learning require elaborate mechanisms for symmetric backpropagation of errors that are biologically implausible. Here the authors propose a simple resolution to this problem of blame assignment that works even with feedback using random synaptic weights.},
	isbn={2041-1723},
	url={https://www.nature.com/articles/ncomms13276},
	doi={10.1038/ncomms13276}
}

@article{RefWorks:RefID:10-grossberg1987competitive,
	author={Stephen Grossberg},
	year={1987},
	month={January 1,},
	title={Competitive learning: From interactive activation to adaptive resonance},
	journal={Cognitive Science},
	volume={11},
	number={1},
	pages={23-63},
	abstract={Functional and mechanistic comparisons are made between several network models of cognitive processing: competitive learning, interactive activation, adaptive resonance, and back propagation. The starting point of this comparison is the article of Rumelhart and Zipser (1985) on feature discovery through competitive learning. All the models which Rumelhart and Zipser (1985) have described were shown in Grossberg (1976b) to exhibit a type of learning which is temporally unstable. Competitive learning mechanisms can be stabilized in response to an arbitrary input environment by being supplemented with mechanisms for learning top-down expectancies, or templates; for matching bottom-up input patterns with the top-down expectancies; and for releasing orienting reactions in a mismatch situation, thereby updating short-term memory and searching for another internal representation. Network architectures which embody all of these mechanisms were called adaptive resonance models by Grossberg (1976c). Self-stabilizing learning models are candidates for use in real-world applications where unpredictable changes can occur in complex input environments. Competitive learning postulates are inconsistent with the postulates of the interactive activation model of McClelland and Rumelhart (1981), and suggest different levels of processing and interaction rules for the analysis of word recognition. Adaptive resonance models use these alternative levels and interaction rules. The selforganizing learning of an adaptive resonance model is compared and contrasted with the teacher-directed learning of a back propagation model. A number of criteria for evaluating real-time network models of cognitive processing are described and applied.},
	isbn={0364-0213},
	url={https://www.sciencedirect.com/science/article/pii/S0364021387800253},
	doi={10.1016/S0364-0213(87)80025-3}
}

@inproceedings{RefWorks:RefID:12-rafati2018improving,
	author={Jacob Rafati and Roummel F. Marcia},
	year={December 2018},
	title={Improving L-BFGS Initialization for Trust-Region Methods in Deep Learning},
	pages={501-508},
	abstract={Deep learning algorithms often require solving a highly non-linear and nonconvex unconstrained optimization problem. Generally, methods for solving the optimization problems in machine learning and in deep learning specifically are restricted to the class of first-order algorithms, like stochastic gradient descent (SGD). The major drawback of the SGD methods is that they have the undesirable effect of not escaping saddle-points. Furthermore, these methods require exhaustive trial-and-error to fine-tune many learning parameters. Using the second-order curvature information to find the search direction can help with more robust convergence for the non-convex optimization problem. However, computing the Hessian matrix for the large-scale problems is not computationally practical. Alternatively, quasi-Newton methods construct an approximate of Hessian matrix to build a quadratic model of the objective function. Quasi-Newton methods, like SGD, require only first-order gradient information, but they can result in superlinear convergence, which makes them attractive alternatives. The limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) approach is one of the most popular quasi-Newton methods that construct positive-definite Hessian approximations. Since the true Hessian matrix is not necessarily positive definite, an extra initialization condition is required to be introduced when constructing the L-BFGS matrices to avoid false negative curvature information. In this paper, we propose various choices for initialization methods of the L-BFGS matrices within a trust-region framework. We provide empirical results on the classification task of the MNIST digits dataset to compare the performance of the trust-region algorithm with different L-BFGS initialization methods.},
	doi={10.1109/ICMLA.2018.00081}
}

@article{RefWorks:RefID:13-johansson1991backpropagation,
	author={E. m. Johansson and F. u. Dowla and D. m. Goodman},
	year={1991},
	month={January 1,},
	title={Backpropagation learning for multilayer feed-forward neural networks using the conjugate gradient method},
	journal={International Journal of Neural Systems},
	volume={02},
	number={04},
	pages={291-301},
	abstract={In many applications, the number of interconnects or weights in a neural network is so large that the learning time for the conventional backpropagation algorithm can become excessively long. Numerical optimization theory offers a rich and robust set of techniques which can be applied to neural networks to improve learning rates. In particular, the conjugate gradient method is easily adapted to the backpropagation learning problem. This paper describes the conjugate gradient method, its application to the backpropagation learning problem and presents results of numerical tests which compare conventional backpropagation, steepest descent and the conjugate gradient methods. For the parity problem, we find that the conjugate gradient method is an order of magnitude faster than conventional backpropagation with momentum.},
	isbn={0129-0657},
	url={https://www.worldscientific.com/doi/abs/10.1142/S0129065791000261},
	doi={10.1142/S0129065791000261}
}

@article{RefWorks:RefID:14-bisong2017benchmarking,
	author={Ekaba Bisong},
	year={2017},
	month={December 22,},
	title={Benchmarking Decoupled Neural Interfaces with Synthetic Gradients},
	abstract={Artifical Neural Network are a particular class of learning system modeled after biological neural functions with an interesting penchant for Hebbian learning, that is "neurons that wire together, fire together". However, unlike their natural counterparts, artificial neural networks have a close and stringent coupling between the modules of neurons in the network. This coupling or locking imposes upon the network a strict and inflexible structure that prevent layers in the network from updating their weights until a full feed-forward and backward pass has occurred. Such a constraint though may have sufficed for a while, is now no longer feasible in the era of very-large-scale machine learning, coupled with the increased desire for parallelization of the learning process across multiple computing infrastructures. To solve this problem, synthetic gradients (SG) with decoupled neural interfaces (DNI) are introduced as a viable alternative to the backpropagation algorithm. This paper performs a speed benchmark to compare the speed and accuracy capabilities of SG-DNI as over to a standard neural interface using multilayer perceptron MLP. SG-DNI shows good promise, in that it not only captures the learning problem, it is also over 3-fold faster due to it asynchronous learning capabilities.}
}