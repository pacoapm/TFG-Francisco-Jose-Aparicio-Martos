@article{RefWorks:RefID:4-schuman2022opportunities,
	author={Catherine D. Schuman and Shruti R. Kulkarni and Maryam Parsa and J. Parker Mitchell and Prasanna Date and Bill Kay},
	year={2022},
	month={-01},
	title={Opportunities for neuromorphic computing algorithms and applications},
	journal={Nature Computational Science},
	volume={2},
	number={1},
	pages={10-19},
	abstract={There is still a wide variety of challenges that restrict the rapid growth of neuromorphic algorithmic and application development. Addressing these challenges is essential for the research community to be able to effectively use neuromorphic computers in the future.},
	isbn={2662-8457},
	url={https://www.nature.com/articles/s43588-021-00184-y},
	doi={10.1038/s43588-021-00184-y}
}

@article{RefWorks:RefID:6-rumelhart1986learning,
	author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
	year={1986},
	month={Oct 9,},
	title={Learning representations by back-propagating errors},
	journal={Nature (London)},
	volume={323},
	number={6088},
	pages={533-536},
	abstract={We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	isbn={0028-0836},
	url={http://dx.doi.org/10.1038/323533a0},
	doi={10.1038/323533a0}
}

@article{RefWorks:RefID:8-lillicrap2020backpropagation,
	author={Timothy P. Lillicrap and Adam Santoro and Luke Marris and Colin J. Akerman and Geoffrey Hinton},
	year={2020},
	month={-06},
	title={Backpropagation and the brain},
	journal={Nature Reviews Neuroscience},
	volume={21},
	number={6},
	pages={335-346},
	abstract={The backpropagation of error (backprop) algorithm is frequently used to train deep neural networks in machine learning, but it has not been viewed as being implemented by the brain. In this Perspective, however, Lillicrap and colleagues argue that the key principles underlying backprop may indeed have a role in brain function.},
	isbn={1471-0048},
	url={https://www.nature.com/articles/s41583-020-0277-3},
	doi={10.1038/s41583-020-0277-3}
}

@article{RefWorks:RefID:9-lillicrap2016random,
	author={Timothy P. Lillicrap and Daniel Cownden and Douglas B. Tweed and Colin J. Akerman},
	year={2016},
	month={-11-08},
	title={Random synaptic feedback weights support error backpropagation for deep learning},
	journal={Nature Communications},
	volume={7},
	number={1},
	pages={1-10},
	abstract={Multi-layered neural architectures that implement learning require elaborate mechanisms for symmetric backpropagation of errors that are biologically implausible. Here the authors propose a simple resolution to this problem of blame assignment that works even with feedback using random synaptic weights.},
	isbn={2041-1723},
	url={https://www.nature.com/articles/ncomms13276},
	doi={10.1038/ncomms13276}
}

@article{RefWorks:RefID:10-grossberg1987competitive,
	author={Stephen Grossberg},
	year={1987},
	month={January 1,},
	title={Competitive learning: From interactive activation to adaptive resonance},
	journal={Cognitive Science},
	volume={11},
	number={1},
	pages={23-63},
	abstract={Functional and mechanistic comparisons are made between several network models of cognitive processing: competitive learning, interactive activation, adaptive resonance, and back propagation. The starting point of this comparison is the article of Rumelhart and Zipser (1985) on feature discovery through competitive learning. All the models which Rumelhart and Zipser (1985) have described were shown in Grossberg (1976b) to exhibit a type of learning which is temporally unstable. Competitive learning mechanisms can be stabilized in response to an arbitrary input environment by being supplemented with mechanisms for learning top-down expectancies, or templates; for matching bottom-up input patterns with the top-down expectancies; and for releasing orienting reactions in a mismatch situation, thereby updating short-term memory and searching for another internal representation. Network architectures which embody all of these mechanisms were called adaptive resonance models by Grossberg (1976c). Self-stabilizing learning models are candidates for use in real-world applications where unpredictable changes can occur in complex input environments. Competitive learning postulates are inconsistent with the postulates of the interactive activation model of McClelland and Rumelhart (1981), and suggest different levels of processing and interaction rules for the analysis of word recognition. Adaptive resonance models use these alternative levels and interaction rules. The selforganizing learning of an adaptive resonance model is compared and contrasted with the teacher-directed learning of a back propagation model. A number of criteria for evaluating real-time network models of cognitive processing are described and applied.},
	isbn={0364-0213},
	url={https://www.sciencedirect.com/science/article/pii/S0364021387800253},
	doi={10.1016/S0364-0213(87)80025-3}
}