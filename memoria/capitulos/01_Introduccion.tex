\chapter{Introducción}
Uno de los grandes retos de la humanidad es la gestión de las inmensas cantidades de datos generados por la digitalización de la información, los avances tecnológicos y el uso intensivo de redes sociales, los cuales solo pueden ser tratados por las técnicas de machine learning. En este campo los algoritmos que más éxito tienen son los conocidos como \textbf{redes neuronales} cuyo propósito es el de procesar la información, ``aprender'' de ella y ofrecer un resultado que dependerá del problema abarcado: clasificación, regresión o una combinación de ambos. 

Para poder resolver problemas que cada vez son más complejos, procesar las grandes cantidades de información y realizar ejecuciones en tiempo real debido a las características de ciertos problemas a resolver, se necesita que el hardware avance y permita una mayor potencia, una mayor paralelización y un mayor rendimiento energético. Estas necesidades son difíciles de satisfacer debido a varios obstáculos como son la ralentización de la ley de Moore, el memory wall problem, que consiste en la brecha de velocidad que hay entre memoria y procesamiento, la separación entre ambas unidades debido a la arquitectura de Von Neumann, y el alto consumo energético de los procesos de entrenamiento muy contaminantes para el medio ambiente. Como consecuencia de estos problemas un campo que está emergiendo y es cada día más importante es el de la \textbf{computación neuromórfica} \cite{RefWorks:RefID:4-schuman2022opportunities}. 

\section{Computación neuromórfica: ventajas e inconvenientes}
La computación neuromórfica es un nuevo tipo de computación la cual no se basa en la clásica arquitectura Von Nuemann en la que memoria y procesamiento se encuentran separados. Este tipo de ordenadores se inspiran en el funcionamiento de nuestro cerebro y se componen de neuronas y sinapsis. 

El aspecto clave de la computación neuromórfica es el IMC (in memory computation), es decir, que tanto procesamiento como almacenamiento se llevan a cabo en el mismo lugar, dando como resultado un descenso en el tiempo computacional. Además de resolver el problema del memory wall, tiene otras características las cuales hacen de la computación neuromórfica una muy buena opción para las redes neuronales. 
\begin{enumerate}
    \item \textbf{Alto nivel de paralelismo}: debido a que los ordenadores neuromórficos se componen de neuronas y éstas pueden trabajar simultáneamente.
    \item \textbf{Escalabilidad inherente}: Los ordenadores neuromórficos se pueden escalar fácilmente añadiendo más chips que incrementan el número de neuronas y sinapsis para poder albergar redes neuronales de mayor amplitud y profundidad.
    \item \textbf{Computación dirigida por eventos}: significa que las neuronas no consumen prácticamente energía hasta que los datos estén listos para ser procesados, lo que hace a los ordenadores neuromórficos altamente eficientes.
    \item \textbf{Estocasticidad}: debido al ruido existente en los circuitos se pueden añadir aleatoriedad de manera sencilla.
\end{enumerate}

Todas estas propiedades hacen que la computación neuromórfica sea una opción idílica para las redes neuronales, pero hoy en día tiene una restricción muy importante y es su escasa precisión numérica (1-3 bits). Como consecuencia los algoritmos y arquitecturas de redes neuronales no obtienen el mismo rendimiento que en arquitecturas Von Neumann.

\section{Justificación del proyecto}
Debido a la importancia que tiene la computación neuromórfica en el futuro de la inteligencia artificial, a la continua investigación que hay por mejorar el rendimiento de estos dispositivos y al importante papel que tienen las redes neuronales actualmente y a futuro en el campo del machine learning, mi proyecto Fin de Grado va a consistir en estudiar cuales son los mejores algoritmos de entrenamiento para redes neuronales en los circuitos neuromórficos. 

\section{Objetivos del proyecto}
Introducida la temática y las motivaciones para el desarrollo, me dispongo a describir los objetivos que se deberán de cumplir para completar el proyecto.

El \textbf{objetivo general} del proyecto es realizar un estudio del comportamiento de los algoritmos de entrenamiento de redes neuronales en circuitos neuromórficos. Para poder alcanzarlo antes debemos de definir los sub-objetivos que lo componen.  

En primer lugar para poder realizar el estudio necesitaré de un repertorio de algoritmos de entrenamiento que estudiar y evaluar, es por ello que el primer objetivo \textbf{OBJ1} será buscar en la literatura los algoritmos alternativos a backpropagation, que será el algoritmo de comparación base. Tras esto, tendré que analizarlos teóricamente por lo que el segundo objetivo \textbf{OBJ2} será obtener la complejidad computacional de los algoritmos seleccionados. 

Hecho el análisis teórico tendré que realizar la comparación de sus rendimientos, tanto a nivel de tiempo de ejecución como obtención de resultados, así que el tercer objetivo \textbf{OBJ3} será realizar la comparación de 3 de los algoritmos más prometedores. Con el ganador de esta comparativa haré una implementación para que funcione en circuitos neuromórficos por lo que el cuarto objetivo \textbf{OBJ4} será realizar una implementación del algoritmo ganador en un circuito neuromórfico. 

Finalmente con la implementación y los resultados de los experimentos realizaré una evaluación del desempeño del algoritmo y valorar si es posible el entrenamiento de redes neuronales en este tipo de circuitos a día de hoy. Por lo tanto, el último objetivo \textbf{OBJ5} es sacar conclusiones de los experimentos y valorar el entrenamiento de redes neuronales cuantizadas en circuitos neuromórficos

\section{Estructura de la memoria}

La memoria está dividida en X capítulos:
\begin{itemize}
    \item Capítulo 1. \textbf{Introducción}. En este capítulo se introduce el proyecto explicando el problema existente y la motivación para su desarrollo.
\end{itemize}