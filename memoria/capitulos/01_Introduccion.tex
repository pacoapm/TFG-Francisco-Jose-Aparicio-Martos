\chapter{Introducción} \label{introduccion}
Uno de los grandes retos de la humanidad es la gestión de las inmensas cantidades de datos generados por la digitalización de la información, los avances tecnológicos y el uso intensivo de redes sociales. Para abordar esa cantidad de datos es necesario usar técnicas informáticas, en particular, el aprendizaje automático o machine learning. En este campo los algoritmos que más éxito tienen son los conocidos como \textbf{redes neuronales}. Su propósito es el de procesar la información, ``aprender'' de ella y ofrecer un resultado que dependerá del problema abarcado: clasificación, regresión o una combinación de ambos. 

Para poder resolver problemas que cada vez son más complejos, procesar las grandes cantidades de información y realizar ejecuciones en tiempo real, se necesita que el hardware avance y permita una mayor potencia, una mayor paralelización y un mayor rendimiento energético. Estas necesidades son difíciles de satisfacer debido a varios obstáculos como son: la ralentización de la ley de Moore \cite{eeckhout2017moore}; el problema de la barrera de la memoria o memory wall problem \cite{10.1145/977091.977115}, brecha de velocidad que hay entre memoria y procesamiento; y el alto consumo energético de los procesos de entrenamiento, muy contaminantes para el medio ambiente \cite{RefWorks:RefID:25-dhar2020the}. Debido a estos problemas un campo que está emergiendo y es cada día más importante es el de la \textbf{computación neuromórfica} \cite{RefWorks:RefID:4-schuman2022opportunities}. 

\section{Computación neuromórfica: ventajas e inconvenientes}
La computación neuromórfica es un nuevo tipo de computación la cual no se basa en la clásica arquitectura Von Neumann en la que memoria y procesamiento se encuentran separados. Este tipo de ordenadores se inspiran en el funcionamiento de nuestro cerebro y se componen de neuronas y sinapsis. 

El aspecto clave de la computación neuromórfica es el IMC (in memory computing), es decir, que tanto procesamiento como almacenamiento se llevan a cabo en el mismo lugar, dando como resultado un descenso en el tiempo computacional. Además de resolver el problema del memory wall, tiene otras características las cuales hacen de la computación neuromórfica una muy buena opción para las redes neuronales. 
\begin{enumerate}
    \item \textbf{Alto nivel de paralelismo}: debido a que los ordenadores neuromórficos se componen de neuronas y éstas pueden trabajar simultáneamente.
    \item \textbf{Escalabilidad inherente}: Los ordenadores neuromórficos se pueden escalar fácilmente añadiendo más chips que incrementan el número de neuronas y sinapsis para poder albergar redes neuronales de mayor amplitud y profundidad.
    \item \textbf{Computación dirigida por eventos}: significa que las neuronas no consumen prácticamente energía hasta que los datos estén listos para ser procesados, lo que hace a los ordenadores neuromórficos altamente eficientes.
    \item \textbf{Estocasticidad}: debido al ruido existente en los circuitos se pueden añadir aleatoriedad de manera sencilla.
\end{enumerate}

Todas estas propiedades hacen que la computación neuromórfica sea una opción idílica para las redes neuronales, pero hoy en día tiene una restricción muy importante y es su escasa precisión numérica (1-3 bits). Como consecuencia los algoritmos y arquitecturas de redes neuronales no obtienen el mismo rendimiento que en arquitecturas Von Neumann.

\section{Justificación del proyecto}
Debido a la importancia que tiene la computación neuromórfica en el futuro de la inteligencia artificial, a la continua investigación que hay por mejorar el rendimiento de estos dispositivos y al importante papel que tienen las redes neuronales actualmente y a futuro en el campo del machine learning, mi proyecto Fin de Grado va a consistir en estudiar como se comportan varios algoritmos de entrenamiento para redes neuronales en los circuitos neuromórficos. 

\section{Objetivos del proyecto}
Introducida la temática y las motivaciones para el desarrollo, me dispongo a describir los objetivos que se deberán de cumplir para completar el proyecto.

El \textbf{objetivo general} del proyecto es realizar un estudio del comportamiento de los algoritmos de entrenamiento de redes neuronales en circuitos neuromórficos. Para poder alcanzarlo antes debemos de definir las sub-tareas tendremos que realizar.  

En primer lugar para poder realizar el estudio necesitaré de un repertorio de algoritmos de entrenamiento que estudiar y evaluar, es por ello que la primera tarea \textbf{T1} será buscar en la literatura los algoritmos alternativos a backpropagation, que será el algoritmo de comparación base. Tras esto, tendré que analizarlos teóricamente por lo que la segunda tarea \textbf{T2} será obtener la complejidad computacional de los algoritmos seleccionados. 

Hecho el análisis teórico se realizará la comparación de sus rendimientos con precisión numérica completa y con la precisión numérica reducida, \textbf{T3}. 

Finalmente con la implementación y los resultados de los experimentos realizaré una evaluación del desempeño de los algoritmos y valoraré si es posible a día de hoy el entrenamiento de redes neuronales en este tipo de circuitos, \textbf{T4}.

\section{Estructura de la memoria}

La memoria se compone de 6 capítulos. Este primer Capítulo \ref{introduccion} realiza una introducción a la temática del proyecto y expone los motivos de su realización. Tras esta breve introducción, se muestra el capítulo de Preliminares \ref{preliminares} en el que se realiza una revisión del estado del arte de las redes neuronales, la cuantificación de las mimas y sobre la computación neuromórfica, además se presentarán: los algoritmos seleccionados mostrando su pseudocódigo y análisis algorítmico; las funciones de cuantificación a usar; y una breve definición sobre qué son los memristores. Establecidas las bases teóricas el siguiente Capítulo \ref{planificacion} presenta la planificación del proyecto, mostrando la metodología a seguir durante el desarrollo del proyecto, los recursos usados y el presupuesto necesario para su elaboración. Los siguientes capítulos tratan sobre la experimentación, en el Capítulo \ref{metodologia} se definen los experimentos a realizar, como se van a realizar los análisis, qué conjuntos de datos se van a usar durante la experimentación y que herramientas se van a emplear. En el Capítulo \ref{implementacion} se muestran como se han realizado las experimentaciones y los resultados juntos a sus valoraciones. La memoria concluye con el Capítulo \ref{conclusion} en el que se realiza una valoración sobre el trabajo realizado en el que se valora los resultados obtenidos y se muestran las vías de trabajo futuro sobre el tema.
