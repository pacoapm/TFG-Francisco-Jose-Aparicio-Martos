\chapter{Introducción}
Hoy en día debido a los avances tecnológicos, a la digitalización de la información y al uso intensivo de redes sociales se está generando inmensas cantidades de datos inabarcables por el ser humano y que solo pueden ser tratados por las técnicas de machine learning.  

Dentro de este campo los algoritmos que más éxito tienen son los conocidos como \textbf{redes neuronales}. Su propósito es el de procesar la información, ``aprender'' de ella y ofrecer un resultado que dependerá de su diseño, pudiendo ser una predicción numérica (problemas de regresión), una clasificación (problemas de clasificación) o una combinación de los anteriores. 

Para que las redes puedan resolver problemas cada vez más complejos necesitan un incremento en la potencia computacional que les permita analizar la mayor cantidad de datos posibles. Además, debido a la naturaleza de ciertos problemas a resolver se necesitan que estas redes se puedan ejecutar en tiempo real, como es el caso de la conducción autónoma de vehículos. Estas necesidades son cada vez más difíciles de satisfacer debido principalmente a varios problemas como son la ralentización de la ley de Moore, el memory wall problem, que consiste en la brecha de velocidad que hay entre memoria y procesamiento, la separación entre ambas unidades debido a la arquitectura de Von Neumann, y el alto consumo energético de los procesos de entrenamiento los cuales son muy contaminantes. Debido a todos estos problemas un campo que está emergiendo y es cada día más importante es el de la \textbf{computación neuromórfica}. 

\section{Computación neuromórfica: ventajas e inconvenientes}
La computación neuromórfica es un nuevo tipo de computación la cual no se basa en la clásica arquitectura Von Nuemann en la que memoria y procesamiento se encuentran separados. Este tipo de ordenadores se inspiran en el funcionamiento de nuestro cerebro y se componen de neuronas y sinapsis. 

El aspecto clave de la computación neuromórfica es el IMC (in memory computation), es decir, que tanto procesamiento como almacenamiento se llevan a cabo en el mismo lugar, dando como resultado un descenso en el tiempo computacional. Además de resolver el problema del memory wall, tiene otras características las cuales hacen de la computación neuromórfica una muy buena opción para las redes neuronales. 
\begin{enumerate}
    \item \textbf{Alto nivel de paralelismo}: debido a que los ordenadores neuromórficos se componen de neuronas y éstas pueden trabajar simultáneamente.
    \item \textbf{Escalabilidad inherente}: Los ordenadores neuromórficos se pueden escalar fácilmente añadiendo más chips que incrementan el número de neuronas y sinapsis para poder albergar redes neuronales de mayor amplitud y profundidad.
    \item \textbf{Computación dirigida por eventos}: significa que las neuronas no consumen prácticamente energía hasta que los datos estén listos para ser procesados, lo que hace a los ordenadores neuromórficos altamente eficientes.
    \item \textbf{Estocasticidad}: debido al ruido existente en los circuitos se pueden añadir aleatoriedad de manera sencilla.
\end{enumerate}

Todas estas propiedades hacen que la computación neuromórfica sea una opción idílica para las redes neuronales, pero hoy en día tiene una restricción muy importante y es su escasa precisión numérica (1-3 bits). Como consecuencia los algoritmos y arquitecturas de redes neuronales no obtienen el mismo rendimiento que en arquitecturas Von Neumann.

\section{Justificación del proyecto}
Debido a la importancia que tiene la computación neuromórfica en el futuro de la inteligencia artificial, a la continua investigación que hay por mejorar el rendimiento de estos dispositivos y al importante papel que tienen las redes neuronales actualmente y a futuro en el campo del machine learning, mi proyecto Fin de Grado va a consistir en estudiar cuales son los mejores algoritmos de entrenamiento para redes neuronales en los circuitos neuromórficos. 





\newpage
Aquí comienza bien